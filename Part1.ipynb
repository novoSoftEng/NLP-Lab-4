{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "333668a0-286d-4435-b81f-caa983914ded",
   "metadata": {},
   "source": [
    "# Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2abd3f1c-c8a5-4f39-9b1d-d2c41638b3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import re\n",
    "from nltk.tokenize import wordpunct_tokenize\n",
    "import nltk\n",
    "from nltk.stem.isri import ISRIStemmer\n",
    "import pandas as pd \n",
    "import random\n",
    "import pyarabic.trans\n",
    "from nltk.tokenize import wordpunct_tokenize\n",
    "import nltk\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c60c00-6b88-4f8c-b51a-a7b05057a886",
   "metadata": {},
   "source": [
    "# Part1 Classification Regression:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1776de61-06ef-4ecc-8366-969c9a8af6f6",
   "metadata": {},
   "source": [
    "## Scraping :  \n",
    "*chosen Topic* : Court judjment on israel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1efe7813-36dc-470c-b7a7-d951ae92f016",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(\"output.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c90e13f9-20bf-41fb-ae1d-94a87c732bee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.aljazeera.net/politics</td>\n",
       "      <td>ضمن فصول جديدة من صراع القوى العالمية على القا...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.aljazeera.net/health/</td>\n",
       "      <td>كشفت دراسة أميركية أن تناول الكثير من الأطعمة ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.aljazeera.net/opinion/</td>\n",
       "      <td>أمام غطرسة السلطة الرئاسية وتماديها في تهديد ا...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.aljazeera.net/where/europe/ukraine/</td>\n",
       "      <td>نقلت وكالة رويترز عن مصادر روسية أن الرئيس فلا...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.aljazeera.net/africa-2</td>\n",
       "      <td>يتناول التحقيق كيف يدعم ويمول الاتحاد الأوروبي...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               url  \\\n",
       "0               https://www.aljazeera.net/politics   \n",
       "1                https://www.aljazeera.net/health/   \n",
       "2               https://www.aljazeera.net/opinion/   \n",
       "3  https://www.aljazeera.net/where/europe/ukraine/   \n",
       "4               https://www.aljazeera.net/africa-2   \n",
       "\n",
       "                                                text  \n",
       "0  ضمن فصول جديدة من صراع القوى العالمية على القا...  \n",
       "1  كشفت دراسة أميركية أن تناول الكثير من الأطعمة ...  \n",
       "2  أمام غطرسة السلطة الرئاسية وتماديها في تهديد ا...  \n",
       "3  نقلت وكالة رويترز عن مصادر روسية أن الرئيس فلا...  \n",
       "4  يتناول التحقيق كيف يدعم ويمول الاتحاد الأوروبي...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57fbae45-d8f8-4214-8307-2aad9095af8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(inplace=True)\n",
    "df.drop(columns=[\"url\"] , inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42491901-f6ae-4039-be52-f7f19b1735f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calculate_relevance(tokens):\n",
    "    # Define relevant keywords\n",
    "    relevant_keywords = [\n",
    "    'محكمة', 'إسرائيل', 'انتهاك', 'قرار', 'دولي', 'حكم', 'قانون', 'قضائي', 'دعوى', \n",
    "    'قضية', 'محاكمة', 'عدالة', 'إدانة', 'قانوني', 'احتلال', 'الشرعية', \n",
    "    'الإجراءات', 'حقوق الإنسان', 'الاتهام', 'العقوبة', 'الاستئناف', 'الجلسة',  'الإسرائيلي', 'القضائية', 'السيادة', 'التحكيم', 'المحامين', 'العدالة'\n",
    "    ]\n",
    "    score = 1\n",
    "    if 'إسرائيل' or 'الإسرائيلي' in tokens:\n",
    "        for token in tokens:\n",
    "            if token in relevant_keywords:\n",
    "                score += 1\n",
    "    return score\n",
    "\n",
    "def rate_text(text):\n",
    "    tokens= wordpunct_tokenize(text)\n",
    "    relevance_score = calculate_relevance(tokens)\n",
    "    return min(10, relevance_score)\n",
    "\n",
    "# Apply the rating function to the DataFrame\n",
    "df['score'] = df['text'].apply(rate_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da36fe9a-a642-4084-976c-6eb3a03100e6",
   "metadata": {},
   "source": [
    "### Load data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "932bf531-09cd-452e-ba71-bcdb7188e62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89f5ba58-7a2f-44d7-8e7f-582e052973e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>ضمن فصول جديدة من صراع القوى العالمية على القا...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>كشفت دراسة أميركية أن تناول الكثير من الأطعمة ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>أمام غطرسة السلطة الرئاسية وتماديها في تهديد ا...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>نقلت وكالة رويترز عن مصادر روسية أن الرئيس فلا...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>يتناول التحقيق كيف يدعم ويمول الاتحاد الأوروبي...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text  score\n",
       "0           0  ضمن فصول جديدة من صراع القوى العالمية على القا...     10\n",
       "1           1  كشفت دراسة أميركية أن تناول الكثير من الأطعمة ...      1\n",
       "2           2  أمام غطرسة السلطة الرئاسية وتماديها في تهديد ا...      1\n",
       "3           3  نقلت وكالة رويترز عن مصادر روسية أن الرئيس فلا...      2\n",
       "4           4  يتناول التحقيق كيف يدعم ويمول الاتحاد الأوروبي...      3"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b8f32dcd-6286-4457-b7f3-59fe12b79532",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_arabic_text(text):\n",
    "    text = str(text)\n",
    "    #Remove \\n\n",
    "    text=re.sub(r'\\n', '', text)\n",
    "    # Remove links\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    # Remove emails\n",
    "    text = re.sub(r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b', '', text)\n",
    "    \n",
    "    # Remove phone numbers\n",
    "    text = re.sub(r'\\b(?:0|\\+?44)[\\d\\s-]{9,13}\\b', '', text)\n",
    "    \n",
    "    # Remove any remaining non-word characters\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    # Segment the text into Arabic and non-Arabic parts\n",
    "    segmented_text = pyarabic.trans.segment_language(text)\n",
    "    \n",
    "    # Concatenate only the Arabic parts\n",
    "    arabic_text = ''.join([segment[1] for segment in segmented_text if segment[0] == 'arabic'])\n",
    "    \n",
    "    # Remove extra spaces\n",
    "    arabic_text = re.sub(r'\\s+', ' ', arabic_text)\n",
    "    \n",
    "    return arabic_text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e6eb703-1e28-420a-8b31-9603037437ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    return wordpunct_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af9e9289-74e6-43bf-84d7-6587dfa5de5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def del_stop_words(tokens):\n",
    "    arb_stopwords = set(nltk.corpus.stopwords.words(\"arabic\"))\n",
    "    filtered_tokens = [token for token in tokens if token not in arb_stopwords]\n",
    "    return filtered_tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a669b37d-a484-4591-9f5c-a76d6c501edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem(tokens):\n",
    "    st = ISRIStemmer()\n",
    "    stemmed_tokens = []\n",
    "    for token in tokens:\n",
    "        stemmed_token = st.stem(token)\n",
    "        stemmed_tokens.append(stemmed_token)\n",
    "    return stemmed_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bf3da707-eaab-49e0-8615-704e6b52ad08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline(df): \n",
    "    df[\"text\"] = df[\"text\"].apply(clean_arabic_text)\n",
    "    df[\"text_tokenized\"] = df[\"text\"].apply(tokenize)\n",
    "    df[\"text_tokenized\"] = df[\"text_tokenized\"].apply(del_stop_words) \n",
    "    df[\"text_stem\"] = df[\"text_tokenized\"].apply(stem)\n",
    "    return df\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "03a5dcbe-2a6e-4b3b-95a0-5f985c455f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pipeline(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "788481f7-106b-4980-be78-d2e1cb8aa4e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>score</th>\n",
       "      <th>text_tokenized</th>\n",
       "      <th>text_stem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>ضمن فصول جديدة من صراع القوى العالمية على القا...</td>\n",
       "      <td>10</td>\n",
       "      <td>[ضمن, فصول, جديدة, صراع, القوى, العالمية, القا...</td>\n",
       "      <td>[ضمن, فصل, جدد, صرع, قوى, علم, قرة, راء, برز, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>كشفت دراسة أميركية أن تناول الكثير من الأطعمة ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[كشفت, دراسة, أميركية, تناول, الكثير, الأطعمة,...</td>\n",
       "      <td>[كشف, درس, امر, نول, كثر, طعم, علج, رقق, بطط, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>أمام غطرسة السلطة الرئاسية وتماديها في تهديد ا...</td>\n",
       "      <td>1</td>\n",
       "      <td>[غطرسة, السلطة, الرئاسية, وتماديها, تهديد, الم...</td>\n",
       "      <td>[غطرس, سلط, رئس, تمد, هدد, سار, ديمقراطي, وصل,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>نقلت وكالة رويترز عن مصادر روسية أن الرئيس فلا...</td>\n",
       "      <td>2</td>\n",
       "      <td>[نقلت, وكالة, رويترز, مصادر, روسية, الرئيس, فل...</td>\n",
       "      <td>[نقل, وكل, رويترز, صدر, روس, رئس, فلاديمير, بو...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>يتناول التحقيق كيف يدعم ويمول الاتحاد الأوروبي...</td>\n",
       "      <td>3</td>\n",
       "      <td>[يتناول, التحقيق, يدعم, ويمول, الاتحاد, الأورو...</td>\n",
       "      <td>[نول, حقق, دعم, يمل, تحد, ورب, بعض, دول, عمل, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text  score  \\\n",
       "0           0  ضمن فصول جديدة من صراع القوى العالمية على القا...     10   \n",
       "1           1  كشفت دراسة أميركية أن تناول الكثير من الأطعمة ...      1   \n",
       "2           2  أمام غطرسة السلطة الرئاسية وتماديها في تهديد ا...      1   \n",
       "3           3  نقلت وكالة رويترز عن مصادر روسية أن الرئيس فلا...      2   \n",
       "4           4  يتناول التحقيق كيف يدعم ويمول الاتحاد الأوروبي...      3   \n",
       "\n",
       "                                      text_tokenized  \\\n",
       "0  [ضمن, فصول, جديدة, صراع, القوى, العالمية, القا...   \n",
       "1  [كشفت, دراسة, أميركية, تناول, الكثير, الأطعمة,...   \n",
       "2  [غطرسة, السلطة, الرئاسية, وتماديها, تهديد, الم...   \n",
       "3  [نقلت, وكالة, رويترز, مصادر, روسية, الرئيس, فل...   \n",
       "4  [يتناول, التحقيق, يدعم, ويمول, الاتحاد, الأورو...   \n",
       "\n",
       "                                           text_stem  \n",
       "0  [ضمن, فصل, جدد, صرع, قوى, علم, قرة, راء, برز, ...  \n",
       "1  [كشف, درس, امر, نول, كثر, طعم, علج, رقق, بطط, ...  \n",
       "2  [غطرس, سلط, رئس, تمد, هدد, سار, ديمقراطي, وصل,...  \n",
       "3  [نقل, وكل, رويترز, صدر, روس, رئس, فلاديمير, بو...  \n",
       "4  [نول, حقق, دعم, يمل, تحد, ورب, بعض, دول, عمل, ...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "40cf7b28-8dfd-476d-9120-bce92494ed7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/unamed/.conda/envs/myenv/lib/python3.11/site-packages/torchtext/vocab/__init__.py:4: UserWarning: \n",
      "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
      "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
      "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n",
      "/home/unamed/.conda/envs/myenv/lib/python3.11/site-packages/torchtext/utils.py:4: UserWarning: \n",
      "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
      "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
      "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from collections import defaultdict\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "70429e67-a3dd-42fa-96bb-285f32ab3aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the vocabulary\n",
    "vocab = build_vocab_from_iterator(df[\"text_stem\"], specials=[\"<unk>\"])\n",
    "vocab.set_default_index(vocab[\"<unk>\"])\n",
    "\n",
    "# Tokenize and build the vocabulary\n",
    "tokenized_X = []\n",
    "for sentence in df[\"text_stem\"]:\n",
    "    indices = [vocab[word] for word in sentence]\n",
    "    tokenized_X.append(indices)\n",
    "\n",
    "# Convert the tokenized sentences to tensors and pad them\n",
    "X_tensors = [torch.tensor(sentence, dtype=torch.long) for sentence in tokenized_X]\n",
    "X_padded = pad_sequence(X_tensors, batch_first=True, padding_value=0)\n",
    "\n",
    "# Convert y to tensor\n",
    "y_tensor = torch.tensor(df['score'].values.tolist(), dtype=torch.float32).view(-1, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "02bab7a3-e9de-4743-9ab9-5f139c4845c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[243, 140, 83, 349, 789, 7, 291, 2032, 244, 375, 19, 2497, 639, 126, 51, 45, 153, 42, 284, 2238, 978, 176, 212, 107, 1863, 2, 2, 47, 2239, 48, 52, 197, 712, 4271, 164, 514, 3357, 95, 154, 937, 729, 2864, 349, 2240, 428, 604, 729, 134, 604, 587, 515, 37, 244, 9, 105, 552, 1606, 92, 938, 939, 285, 180, 42, 6, 79, 5, 730, 119, 890, 75, 141, 75, 731, 1126, 2241, 77, 299, 223, 358, 184, 2498, 177, 71, 401, 24, 63, 2499, 63, 170, 2865, 349, 299, 539, 732, 1206, 1607, 27, 15, 3358, 760, 278, 2866, 1719, 6, 3359, 564, 850, 34, 2867, 5, 790, 418, 2500, 2868, 270, 1720, 73, 791, 72, 65, 141, 85, 1608, 6, 236, 16, 165, 9, 105, 1070, 6, 376, 713, 231, 2869, 92, 143, 239, 92, 18, 226, 821, 2033, 76, 181, 105, 1, 618, 666, 473, 114, 402, 49, 3360, 3361, 1127, 55, 383, 312, 730, 279, 159, 143, 77, 144, 851, 1071, 1283, 5, 1428, 14, 95, 761, 143, 73, 27, 212, 48, 2242, 474, 74, 640, 2870, 304, 463, 286, 98, 114, 66, 2243, 940, 377, 11, 229, 2244, 5, 39, 40, 160, 160, 5, 390, 1348, 39, 8, 179, 1027, 390, 8, 1609, 411, 25, 291, 369, 1028, 132, 1511, 2501, 296, 128, 49, 2871, 49, 19, 48, 236, 5, 169, 474, 74, 1128, 35, 2034, 189, 74, 4272, 265, 237, 116, 852, 2872, 313, 314, 73, 251, 321, 89, 230, 24, 339, 3362, 140, 441, 540, 619, 45, 7, 383, 8, 45, 17, 72, 762, 297, 305, 330, 45, 733, 122, 218, 1864, 979, 6, 792, 4273, 51, 6, 553, 172, 442, 4274, 70, 322, 980, 11, 76, 564, 164, 37, 1284, 183, 292, 213, 135, 108, 686, 1, 376, 5, 56, 155, 287, 143, 605, 1207, 2035, 99, 19, 2873, 255, 687, 1, 64, 4275, 3363, 231, 588, 484, 93, 73, 2502, 4276, 227, 5, 54, 853, 15, 565, 340, 136, 178, 54, 3364, 3365, 3366, 212, 196, 47, 19, 641, 412, 23, 17, 43, 429, 315]]\n",
      "[ 243  140   83  349  789    7  291 2032  244  375   19 2497  639  126\n",
      "   51   45  153   42  284 2238  978  176  212  107 1863    2    2   47\n",
      " 2239   48   52  197  712 4271  164  514 3357   95  154  937  729 2864\n",
      "  349 2240  428  604  729  134  604  587  515   37  244    9  105  552\n",
      " 1606   92  938  939  285  180   42    6   79    5  730  119  890   75\n",
      "  141   75  731 1126 2241   77  299  223  358  184 2498  177   71  401\n",
      "   24   63 2499   63  170 2865  349  299  539  732 1206 1607   27   15\n",
      " 3358  760  278 2866 1719    6 3359  564  850   34 2867    5  790  418\n",
      " 2500 2868  270 1720   73  791   72   65  141   85 1608    6  236   16\n",
      "  165    9  105 1070    6  376  713  231 2869   92  143  239   92   18\n",
      "  226  821 2033   76  181  105    1  618  666  473  114  402   49 3360\n",
      " 3361 1127   55  383  312  730  279  159  143   77  144  851 1071 1283\n",
      "    5 1428   14   95  761  143   73   27  212   48 2242  474   74  640\n",
      " 2870  304  463  286   98  114   66 2243  940  377   11  229 2244    5\n",
      "   39   40  160  160]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import string\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Tokenize - Create Vocab to Int\n",
    "corpus = [word for sublist in df['text_stem'] for word in sublist]\n",
    "count_words = Counter(corpus)\n",
    "sorted_words = count_words.most_common()\n",
    "\n",
    "# Plot top 20 most common words (optional)\n",
    "import matplotlib.pyplot as plt\n",
    "keys, values = zip(*sorted_words[:20])\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.bar(keys, values)\n",
    "plt.title('Top 20 most common words')\n",
    "plt.show()\n",
    "\n",
    "# Create vocabulary to integer mapping\n",
    "vocab_to_int = {w: i + 1 for i, (w, c) in enumerate(sorted_words)}\n",
    "\n",
    "# Tokenize - Encode the text\n",
    "text_int = []\n",
    "for text in df['text_stem']:\n",
    "    r = [vocab_to_int[word] for word in text]\n",
    "    text_int.append(r)\n",
    "print(text_int[:1])\n",
    "df['text_done'] = text_int\n",
    "\n",
    "# Padding/Truncating the data\n",
    "def padding(text_int, seq_len):\n",
    "    features = np.zeros((len(text_int), seq_len), dtype=int)\n",
    "    for i, text in enumerate(text_int):\n",
    "        if len(text) <= seq_len:\n",
    "            zeros = list(np.zeros(seq_len - len(text)))\n",
    "            new = zeros + text\n",
    "        else:\n",
    "            new = text[:seq_len]\n",
    "        features[i, :] = np.array(new)\n",
    "    return features\n",
    "\n",
    "# Assuming your sequence length is 200\n",
    "features = padding(text_int, 200)\n",
    "print(features[0, :])\n",
    "\n",
    "# Train-validation-test split\n",
    "X_train, X_remain, y_train, y_remain = train_test_split(features, df['score'].to_numpy(), test_size=0.2, random_state=1)\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_remain, y_remain, test_size=0.5, random_state=1)\n",
    "\n",
    "# Now you have your preprocessed dataset split into training, validation, and test sets.\n",
    "train_data = TensorDataset(torch.from_numpy(X_train), torch.from_numpy(y_train))\n",
    "test_data = TensorDataset(torch.from_numpy(X_test), torch.from_numpy(y_test))\n",
    "valid_data = TensorDataset(torch.from_numpy(X_valid), torch.from_numpy(y_valid))\n",
    "# dataloaders\n",
    "batch_size = 50\n",
    "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size, drop_last=True)\n",
    "test_loader = DataLoader(test_data, shuffle=True, batch_size=batch_size)\n",
    "valid_loader = DataLoader(valid_data, shuffle=True, batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f1ffbb7-e366-400a-8797-14eb82dd8d56",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e45afa1e-1a71-423d-a571-8fadec982c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_RNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size, output_size, embedding_dim, hidden_dim, n_layers, drop_prob=0):\n",
    "        super(LSTM_RNN, self).__init__()\n",
    "        \"\"\"\n",
    "            Initialize the model by setting up the layers.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.output_size = output_size\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        # Embedding and LSTM layers\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, n_layers, dropout=drop_prob,\n",
    "        batch_first=True)\n",
    "        # Dropout layer\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.relu = nn.ReLU()\n",
    "# Linear and sigmoid layers\n",
    "        self.fc = nn.Linear(hidden_dim, output_size)\n",
    "        #self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x, hidden):\n",
    "        \"\"\"\n",
    "        Perform a forward pass of our model on some input and hidden state.\n",
    "        \"\"\"\n",
    "        batch_size = x.size(0)\n",
    "        #embedding and lstm_out\n",
    "        embeds = self.embedding(x)\n",
    "        lstm_out, hidden = self.lstm(embeds, hidden)\n",
    "        #stack up lstm outputs\n",
    "        lstm_out = lstm_out.contiguous().view(-1, self.hidden_dim)\n",
    "        # Dropout and fully connected layer\n",
    "        out = self.dropout(lstm_out)\n",
    "        out  = self.relu(out)\n",
    "        out = self.fc(out)\n",
    "        #sigmoid function\n",
    "        \"\"\"\n",
    "        sig_out = self.sigmoid(out)\n",
    "        # reshape to be batch size first\n",
    "        sig_out = sig_out.view(batch_size, -1)\n",
    "        sig_out = sig_out[:, -1] # get last batch of labels\"\"\"\n",
    "        return out.view(batch_size, -1)[:, -1], hidden\n",
    "    def init_hidden(self, batch_size):\n",
    "    # Create two new tensors with sizes n_layers x batch_size x hidden_dim,\n",
    "    # initialized to zero, for hidden state and cell state of LSTM\n",
    "        h0 = torch.zeros((self.n_layers,batch_size,self.hidden_dim))\n",
    "        c0 = torch.zeros((self.n_layers,batch_size,self.hidden_dim))\n",
    "        hidden = (h0,c0)\n",
    "        return hidden\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2abae4b8-00ab-426f-8852-4145550b9429",
   "metadata": {},
   "source": [
    "## RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "87813524-8669-425f-9c9e-50c1b2dcbcf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, vocab_size, output_size, embedding_dim, hidden_dim, n_layers, drop_prob=0.0):\n",
    "        super(RNN, self).__init__()\n",
    "        \"\"\"\n",
    "        Initialize the model by setting up the layers.\n",
    "        \"\"\"\n",
    "        self.output_size = output_size\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "        # Embedding and RNN layers\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.rnn = nn.RNN(embedding_dim, hidden_dim, n_layers, nonlinearity='tanh', bias=True, batch_first=True, dropout=drop_prob, bidirectional=False)\n",
    "        \n",
    "        # Dropout layer\n",
    "        self.dropout = nn.Dropout(drop_prob)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        # Linear layer\n",
    "        self.fc = nn.Linear(hidden_dim, output_size)\n",
    "    \n",
    "    def forward(self, x, hidden):\n",
    "        \"\"\"\n",
    "        Perform a forward pass of our model on some input and hidden state.\n",
    "        \"\"\"\n",
    "        batch_size = x.size(0)\n",
    "        \n",
    "        # Embedding and RNN\n",
    "        embeds = self.embedding(x)\n",
    "        rnn_out, hidden = self.rnn(embeds, hidden)\n",
    "        \n",
    "        # Stack up RNN outputs\n",
    "        rnn_out = rnn_out.contiguous().view(-1, self.hidden_dim)\n",
    "        \n",
    "        # Dropout and fully connected layer\n",
    "        out = self.dropout(rnn_out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc(out)\n",
    "        \n",
    "        # Reshape to be batch size first\n",
    "        out = out.view(batch_size, -1)[:, -1]\n",
    "        \n",
    "        return out, hidden\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        \"\"\"\n",
    "        Initialize hidden state.\n",
    "        \"\"\"\n",
    "        hidden = torch.zeros(self.n_layers, batch_size, self.hidden_dim)\n",
    "        return hidden\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "016f6971-adc9-4a2c-9af6-cb7d284ceb1f",
   "metadata": {},
   "source": [
    "## Bidirectional RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "93e38fde-c791-4dda-ab37-60a7bef040ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bi_RNN(nn.Module):\n",
    "    def __init__(self, vocab_size, output_size, embedding_dim, hidden_dim, n_layers, drop_prob=0.0):\n",
    "        super(Bi_RNN, self).__init__()\n",
    "        \"\"\"\n",
    "        Initialize the model by setting up the layers.\n",
    "        \"\"\"\n",
    "        self.output_size = output_size\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "        # Embedding and RNN layers\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.rnn = nn.RNN(embedding_dim, hidden_dim, n_layers, nonlinearity='tanh', bias=True, dropout=drop_prob, bidirectional=True)\n",
    "        \n",
    "        # Dropout layer\n",
    "        self.dropout = nn.Dropout(drop_prob)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        # Linear layer\n",
    "        self.fc = nn.Linear(hidden_dim, output_size)\n",
    "    \n",
    "    def forward(self, x, hidden):\n",
    "        \"\"\"\n",
    "        Perform a forward pass of our model on some input and hidden state.\n",
    "        \"\"\"\n",
    "        batch_size = x.size(0)\n",
    "        \n",
    "        # Embedding and RNN\n",
    "        embeds = self.embedding(x)\n",
    "        rnn_out, hidden = self.rnn(embeds, hidden)\n",
    "        \n",
    "        # Stack up RNN outputs\n",
    "        rnn_out = rnn_out.contiguous().view(-1, self.hidden_dim)\n",
    "        \n",
    "        # Dropout and fully connected layer\n",
    "        out = self.dropout(rnn_out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc(out)\n",
    "        \n",
    "        # Reshape to be batch size first\n",
    "        out = out.view(batch_size, -1)[:, -1]\n",
    "        \n",
    "        return out, hidden\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        \"\"\"\n",
    "        Initialize hidden state.\n",
    "        \"\"\"\n",
    "        hidden = torch.zeros(self.n_layers, batch_size, self.hidden_dim)\n",
    "        return hidden\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1bd355-12fe-4756-b5f1-d9f384abc578",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0986564c-e13d-4c2d-9112-08e889e1f0d7",
   "metadata": {},
   "source": [
    "### training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1a5125bc-c093-43d2-ab42-479da33e872f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "def train_rnn_model(rnn,vocab_to_int, train_loader, epochs=10, batch_size=50, lr=0.001 ):\n",
    "    # Instantiate the model with hyperparameters\n",
    "    vocab_size = len(vocab_to_int) + 1\n",
    "    output_size = 1\n",
    "    print(rnn)\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(rnn.parameters(), lr=lr)\n",
    "\n",
    "    for epoch in range(epochs):  # Loop over the dataset multiple times\n",
    "        h = rnn.init_hidden(batch_size)  # Initialize hidden state\n",
    "        rnn.train()\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for i, data in enumerate(train_loader, 0):\n",
    "            inputs, labels = data\n",
    "            labels = labels.float()\n",
    "\n",
    "            # Ensure the hidden state is correctly managed\n",
    "            if isinstance(h, tuple):\n",
    "                h = tuple([each.data for each in h])\n",
    "            else:\n",
    "                h = h.data\n",
    "\n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward + backward + optimize\n",
    "            outputs, h = rnn(inputs, h)\n",
    "            loss = criterion(outputs, labels)\n",
    "            print(\"Current loss:\", loss)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Print statistics\n",
    "            running_loss += loss.item()\n",
    "            if i % 2000 == 1999:  # Print every 2000 mini-batches\n",
    "                print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
    "                running_loss = 0.0\n",
    "\n",
    "    print('Finished Training')\n",
    "    return rnn, optimizer\n",
    "\n",
    "# Example usage:\n",
    "# Assuming vocab_to_int is defined and train_loader is your DataLoader\n",
    "# \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8c613f50-6687-47dc-b45b-90267ed91ba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM_RNN(\n",
      "  (embedding): Embedding(7162, 220)\n",
      "  (lstm): LSTM(220, 300, num_layers=3, batch_first=True)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (relu): ReLU()\n",
      "  (fc): Linear(in_features=300, out_features=1, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/unamed/.conda/envs/myenv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current loss: tensor(13.2547, grad_fn=<MseLossBackward0>)\n",
      "Current loss: tensor(12.9778, grad_fn=<MseLossBackward0>)\n",
      "Current loss: tensor(13.2785, grad_fn=<MseLossBackward0>)\n",
      "Current loss: tensor(15.7135, grad_fn=<MseLossBackward0>)\n",
      "Current loss: tensor(5.7622, grad_fn=<MseLossBackward0>)\n",
      "Current loss: tensor(8.7126, grad_fn=<MseLossBackward0>)\n",
      "Current loss: tensor(8.8047, grad_fn=<MseLossBackward0>)\n",
      "Current loss: tensor(5.2756, grad_fn=<MseLossBackward0>)\n",
      "Current loss: tensor(7.9601, grad_fn=<MseLossBackward0>)\n",
      "Current loss: tensor(10.0714, grad_fn=<MseLossBackward0>)\n",
      "Current loss: tensor(6.4490, grad_fn=<MseLossBackward0>)\n",
      "Current loss: tensor(4.1686, grad_fn=<MseLossBackward0>)\n",
      "Current loss: tensor(5.1051, grad_fn=<MseLossBackward0>)\n",
      "Current loss: tensor(8.5681, grad_fn=<MseLossBackward0>)\n",
      "Current loss: tensor(5.6580, grad_fn=<MseLossBackward0>)\n",
      "Current loss: tensor(3.9880, grad_fn=<MseLossBackward0>)\n",
      "Current loss: tensor(9.6585, grad_fn=<MseLossBackward0>)\n",
      "Current loss: tensor(6.5905, grad_fn=<MseLossBackward0>)\n",
      "Current loss: tensor(3.7585, grad_fn=<MseLossBackward0>)\n",
      "Current loss: tensor(7.3923, grad_fn=<MseLossBackward0>)\n",
      "Current loss: tensor(5.5995, grad_fn=<MseLossBackward0>)\n",
      "Current loss: tensor(3.2600, grad_fn=<MseLossBackward0>)\n",
      "Current loss: tensor(6.6581, grad_fn=<MseLossBackward0>)\n",
      "Current loss: tensor(8.6846, grad_fn=<MseLossBackward0>)\n",
      "Current loss: tensor(2.8795, grad_fn=<MseLossBackward0>)\n",
      "Current loss: tensor(6.1834, grad_fn=<MseLossBackward0>)\n",
      "Current loss: tensor(6.6974, grad_fn=<MseLossBackward0>)\n",
      "Current loss: tensor(2.8487, grad_fn=<MseLossBackward0>)\n",
      "Current loss: tensor(7.4144, grad_fn=<MseLossBackward0>)\n",
      "Current loss: tensor(4.7459, grad_fn=<MseLossBackward0>)\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(vocab_to_int) +1\n",
    "lstm = LSTM_RNN(vocab_size, output_size= 1, embedding_dim=220, hidden_dim=300, n_layers=3)\n",
    "lstm, optimizer = train_rnn_model(lstm,vocab_to_int=vocab_to_int, train_loader=train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "620f89a5-755e-4ea8-9072-16cc31b485e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN(\n",
      "  (embedding): Embedding(7162, 220)\n",
      "  (rnn): RNN(220, 300, num_layers=3, batch_first=True)\n",
      "  (dropout): Dropout(p=0.0, inplace=False)\n",
      "  (relu): ReLU()\n",
      "  (fc): Linear(in_features=300, out_features=1, bias=True)\n",
      ")\n",
      "Current loss: tensor(15.6228, grad_fn=<MseLossBackward0>)\n",
      "Current loss: tensor(11.6631, grad_fn=<MseLossBackward0>)\n",
      "Current loss: tensor(9.0929, grad_fn=<MseLossBackward0>)\n",
      "Current loss: tensor(7.3981, grad_fn=<MseLossBackward0>)\n",
      "Current loss: tensor(4.7010, grad_fn=<MseLossBackward0>)\n",
      "Current loss: tensor(3.7581, grad_fn=<MseLossBackward0>)\n",
      "Current loss: tensor(5.4899, grad_fn=<MseLossBackward0>)\n",
      "Current loss: tensor(5.8573, grad_fn=<MseLossBackward0>)\n",
      "Current loss: tensor(5.1484, grad_fn=<MseLossBackward0>)\n",
      "Current loss: tensor(5.4037, grad_fn=<MseLossBackward0>)\n",
      "Current loss: tensor(6.7296, grad_fn=<MseLossBackward0>)\n",
      "Current loss: tensor(5.7475, grad_fn=<MseLossBackward0>)\n",
      "Current loss: tensor(6.7769, grad_fn=<MseLossBackward0>)\n",
      "Current loss: tensor(2.5806, grad_fn=<MseLossBackward0>)\n",
      "Current loss: tensor(3.3373, grad_fn=<MseLossBackward0>)\n",
      "Current loss: tensor(3.8268, grad_fn=<MseLossBackward0>)\n",
      "Current loss: tensor(2.7598, grad_fn=<MseLossBackward0>)\n",
      "Current loss: tensor(2.6625, grad_fn=<MseLossBackward0>)\n",
      "Current loss: tensor(1.9537, grad_fn=<MseLossBackward0>)\n",
      "Current loss: tensor(2.8191, grad_fn=<MseLossBackward0>)\n",
      "Current loss: tensor(1.8365, grad_fn=<MseLossBackward0>)\n",
      "Current loss: tensor(2.9916, grad_fn=<MseLossBackward0>)\n",
      "Current loss: tensor(1.5122, grad_fn=<MseLossBackward0>)\n",
      "Current loss: tensor(1.6684, grad_fn=<MseLossBackward0>)\n",
      "Current loss: tensor(1.9926, grad_fn=<MseLossBackward0>)\n",
      "Current loss: tensor(1.4709, grad_fn=<MseLossBackward0>)\n",
      "Current loss: tensor(2.1948, grad_fn=<MseLossBackward0>)\n",
      "Current loss: tensor(0.9885, grad_fn=<MseLossBackward0>)\n",
      "Current loss: tensor(1.1802, grad_fn=<MseLossBackward0>)\n",
      "Current loss: tensor(1.5261, grad_fn=<MseLossBackward0>)\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "rnn = RNN(vocab_size, output_size= 1, embedding_dim=220, hidden_dim=300, n_layers=3)\n",
    "rnn, optimizer = train_rnn_model(rnn,vocab_to_int=vocab_to_int, train_loader=train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f123700b-f427-4967-b50b-d17e31957c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "bi_rnn = Bi_RNN(vocab_size, output_size= 1, embedding_dim=220, hidden_dim=300, n_layers=3).cuda()\n",
    "bi_rnn, optimizer = train_rnn_model(bi_rnn,vocab_to_int=vocab_to_int, train_loader=train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "3cc207f4-3def-4650-9668-60f3161a0672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 9.652\n",
      "Mean Squared Error (MSE): 9.417\n",
      "Mean Absolute Error (MAE): 1.833\n",
      "Test Predictions: [1.0, 3.0, 3.0, 1.0, 1.0, 2.0, 2.0, 4.0, 1.0, 2.0, 2.0, 2.0, 3.0, 1.0, 5.0, 4.0, 3.0, 1.0, 1.0, 3.0, 2.0, 1.0, 1.0, 2.0]\n",
      "Test Labels: [1.0, 10.0, 1.0, 1.0, 4.0, 3.0, 2.0, 10.0, 1.0, 2.0, 2.0, 1.0, 5.0, 10.0, 6.0, 1.0, 1.0, 1.0, 1.0, 2.0, 7.0, 1.0, 1.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "def predict(model, test_loader, criterion):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    test_losses = []\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            inputs, labels = data\n",
    "            labels = labels.float()\n",
    "            batch_size = inputs.size(0)\n",
    "            h = model.init_hidden(batch_size)\n",
    "\n",
    "            # Ensure the hidden state is correctly managed\n",
    "            if isinstance(h, tuple):\n",
    "                h = tuple([each.data for each in h])\n",
    "            else:\n",
    "                h = h.data\n",
    "\n",
    "            outputs, h = model(inputs, h)\n",
    "            loss = criterion(outputs.squeeze(), labels)\n",
    "            test_losses.append(loss.item())\n",
    "\n",
    "            # Collect predictions and labels without rounding\n",
    "            preds = torch.round(outputs.squeeze()).tolist()\n",
    "            all_preds.extend(preds)\n",
    "            all_labels.extend(labels.tolist())\n",
    "\n",
    "    avg_test_loss = sum(test_losses) / len(test_losses)\n",
    "    mse = mean_squared_error(all_labels, all_preds)\n",
    "    mae = mean_absolute_error(all_labels, all_preds)\n",
    "\n",
    "    print(f'Test Loss: {avg_test_loss:.3f}')\n",
    "    print(f'Mean Squared Error (MSE): {mse:.3f}')\n",
    "    print(f'Mean Absolute Error (MAE): {mae:.3f}')\n",
    "    \n",
    "    return all_preds, all_labels\n",
    "\n",
    "# Example usage:\n",
    "# Assuming rnn is your model, test_loader is your DataLoader, and criterion is your loss function\n",
    "test_preds, test_labels = predict(rnn, test_loader, criterion)\n",
    "print(\"Test Predictions:\", test_preds)\n",
    "print(\"Test Labels:\", test_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8cb40b6-c740-4f9d-a084-0be3bff18e17",
   "metadata": {},
   "source": [
    "###  RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4816ced2-6606-46ff-860c-04494699321d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
